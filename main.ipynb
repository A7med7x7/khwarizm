{"cells":[{"cell_type":"markdown","metadata":{"id":"GbxChli6A2k1"},"source":["# Importings"]},{"cell_type":"markdown","metadata":{"id":"86s-4DVxA2k2"},"source":["- consider imputing some of the tests\n","- take the LGBM or Catboost Performance o\n","- try different values for clipping"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T07:08:42.064915Z","iopub.status.busy":"2024-09-07T07:08:42.064408Z","iopub.status.idle":"2024-09-07T07:08:42.362566Z","shell.execute_reply":"2024-09-07T07:08:42.361339Z","shell.execute_reply.started":"2024-09-07T07:08:42.064838Z"},"id":"wfN_LZD2A2k2","trusted":true},"outputs":[],"source":["import pandas as pd                                    \n","import numpy as np        \n","import matplotlib.pyplot as plt\n","import seaborn as sns                              \n","from sklearn.cluster import KMeans\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.model_selection import GroupKFold\n","from lightgbm import LGBMRegressor\n","from sklearn.metrics import mean_squared_error\n","\n","class CFG:\n","  data_folder =\"../khwarizm/data/\"\n","\n","def reading_data(path: str) -> pd.DataFrame:\n","  train = pd.read_csv(path + 'Train.csv')\n","  test = pd.read_csv(path + 'Test.csv')\n","  return train,test\n","\n","train,test = reading_data(CFG.data_folder)\n","\n","groups = train['ID']\n","test_id = test['ID_Zindi']\n","train_date = train['Date']\n","test_date = test['Date']\n","test_id = test['ID_Zindi']\n","pd.options.display.max_columns = 200\n","\n","seed = 7 \n","seed2 = 77\n","tiney_fraction = 1e-05\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T07:08:42.496642Z","iopub.status.busy":"2024-09-07T07:08:42.496243Z","iopub.status.idle":"2024-09-07T07:08:42.532208Z","shell.execute_reply":"2024-09-07T07:08:42.530819Z","shell.execute_reply.started":"2024-09-07T07:08:42.496599Z"},"id":"Rg8w61uzA2k3","trusted":true},"outputs":[{"data":{"text/plain":["ID_Zindi                  0\n","Date                      0\n","ID                        0\n","LAT                       0\n","LON                       0\n","Precipitation             0\n","LST                   37594\n","AAI                   12118\n","CloudFraction         12118\n","NO2_strat             12118\n","NO2_total             12118\n","NO2_trop              33429\n","TropopausePressure    12118\n","GT_NO2                    0\n","dtype: int64"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["train = train.dropna(subset=['GT_NO2'])\n","train.isnull().sum()"]},{"cell_type":"markdown","metadata":{"id":"PTg6C2AgA2k4"},"source":["# Feature Engineering"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T07:08:42.534173Z","iopub.status.busy":"2024-09-07T07:08:42.533715Z","iopub.status.idle":"2024-09-07T07:08:42.542349Z","shell.execute_reply":"2024-09-07T07:08:42.541181Z","shell.execute_reply.started":"2024-09-07T07:08:42.534128Z"},"id":"dxYxybSVA2k4","trusted":true},"outputs":[],"source":["groups = train['ID']\n","num_feats = train.select_dtypes(include=['float'])\n","kmeans = KMeans(n_clusters=2)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T07:08:42.544356Z","iopub.status.busy":"2024-09-07T07:08:42.543792Z","iopub.status.idle":"2024-09-07T07:08:45.379689Z","shell.execute_reply":"2024-09-07T07:08:45.378501Z","shell.execute_reply.started":"2024-09-07T07:08:42.544307Z"},"id":"Q4vR1sbXA2k4","trusted":true},"outputs":[],"source":["lat_min, lat_max = 44.92469405, 45.88973369\n","lon_min, lon_max = 8.736496578, 12.59068235\n","\n","num_clusters_lat = 3\n","num_clusters_lon = 4\n","lat_step = (lat_max - lat_min) / num_clusters_lat\n","lon_step = (lon_max - lon_min) / num_clusters_lon\n","def assign_clusters(row, lat_step, lon_step, lat_min, lon_min):\n","    lat_cluster = int((row['LAT'] - lat_min) / lat_step)\n","    lon_cluster = int((row['LON'] - lon_min) / lon_step)\n","    return lat_cluster, lon_cluster\n","for dataset in (train, test):\n","    dataset[['lat_cluster', 'lon_cluster']] = dataset.apply(\n","        assign_clusters, axis=1, result_type='expand',\n","        lat_step=lat_step, lon_step=lon_step, lat_min=lat_min, lon_min=lon_min)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/workspaces/khwarizm/khwarizm/time_series.py:41: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  dataset['date'] = pd.to_datetime(dataset[col])\n","/workspaces/khwarizm/khwarizm/time_series.py:41: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  dataset['date'] = pd.to_datetime(dataset[col])\n"]},{"data":{"text/plain":["Index(['ID_Zindi', 'Date', 'ID', 'LAT', 'LON', 'Precipitation', 'LST', 'AAI',\n","       'CloudFraction', 'NO2_strat', 'NO2_total', 'NO2_trop',\n","       'TropopausePressure', 'GT_NO2', 'lat_cluster', 'lon_cluster', 'date',\n","       'Year', 'month', 'day', 'Weekday', 'Year_week', 'month_day'],\n","      dtype='object')"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["from khwarizm.time_series import time_features\n","\"\"\"\n","this is to get the time related features like year, month, week, day\n","\"\"\"\n","for df in (train,test):\n","    time_features(df)\n","\n","train.columns"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["'class Features:\\n    def __init__(self, dataset:pd.DataFrame,trainset: pd.DataFrame, testset: pd.DataFrame, date_feature: str):\\n        self.dataset = dataset\\n        self.trainset = trainset\\n        self.testset = testset\\n        self.date_feature = date_feature\\n\\n    def rolling_feature( self,feature: str, window: int):\\n        for dataset in (self.trainset, self.testset):\\n            dataset[f\"{feature}_rolling_max_{window}\"] = dataset[feature].rolling(window).max()\\n            return dataset'"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"class Features:\n","    def __init__(self, dataset:pd.DataFrame,trainset: pd.DataFrame, testset: pd.DataFrame, date_feature: str):\n","        self.dataset = dataset\n","        self.trainset = trainset\n","        self.testset = testset\n","        self.date_feature = date_feature\n","\n","    def rolling_feature( self,feature: str, window: int):\n","        for dataset in (self.trainset, self.testset):\n","            dataset[f\"{feature}_rolling_max_{window}\"] = dataset[feature].rolling(window).max()\n","            return dataset\"\"\""]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["from khwarizm.time_series import Features\n","\n","df = pd.concat([train, test])\n","features = Features(dataset=df, trainset=train, testset=test, date_feature='Date')\n","train, test = features.rolling_feature(feature='NO2_trop', window=60)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["(        ID_Zindi      Date     ID        LAT        LON  Precipitation  \\\n"," 0      ID_ENTGC7    1/1/19   PD01  45.601585  11.903551       0.000000   \n"," 1      ID_8JCCXC    1/1/19   PD04  45.371005  11.840830       3.047342   \n"," 2      ID_V3136Z    1/1/19   RO01  45.045825  12.060869       0.000000   \n"," 3      ID_KRVZDJ    1/1/19   RO02  45.104075  11.553241       1.200467   \n"," 4      ID_PR351A    1/1/19   RO03  45.038758  11.790152       1.274564   \n"," ...          ...       ...    ...        ...        ...            ...   \n"," 86579  ID_NCWXIY  31-12-21  X9897  45.498227   9.556232       0.000000   \n"," 86580  ID_UDQIEE  31-12-21  X9928  45.142541  10.043836       0.000000   \n"," 86581  ID_ENDUPX  31-12-21  X9969  45.842207   9.351658       0.000000   \n"," 86582  ID_3ZBA6C  31-12-21  X9993  45.113503   8.874065       0.000000   \n"," 86583  ID_GWG0LD  31-12-21  X9999  45.526473   9.515980       0.000000   \n"," \n","           LST       AAI  CloudFraction  NO2_strat  NO2_total  NO2_trop  \\\n"," 0         NaN  0.230527       0.559117   0.000024   0.000117       NaN   \n"," 1         NaN -0.074006       0.869309   0.000024   0.000127       NaN   \n"," 2         NaN  0.024470       0.674160   0.000024   0.000086       NaN   \n"," 3         NaN -0.010442       0.920054   0.000024   0.000124       NaN   \n"," 4         NaN -0.176178       0.747464   0.000024   0.000116       NaN   \n"," ...       ...       ...            ...        ...        ...       ...   \n"," 86579     NaN -0.434350       0.250490   0.000032   0.000643       NaN   \n"," 86580     NaN       NaN            NaN        NaN        NaN       NaN   \n"," 86581  284.98 -0.157753       0.000000   0.000031   0.000153  0.000122   \n"," 86582     NaN -0.798636       0.399524   0.000031   0.000717       NaN   \n"," 86583     NaN -0.434482       0.250530   0.000032   0.000643       NaN   \n"," \n","        TropopausePressure  GT_NO2  lat_cluster  lon_cluster       date  Year  \\\n"," 0             14440.82126  31.000            2            3 2019-01-01  2019   \n"," 1             14441.79815  42.000            1            3 2019-01-01  2019   \n"," 2             14437.38294  31.000            0            3 2019-01-01  2019   \n"," 3             14440.83831  30.000            0            2 2019-01-01  2019   \n"," 4             14438.79037  58.000            0            3 2019-01-01  2019   \n"," ...                   ...     ...          ...          ...        ...   ...   \n"," 86579         13063.79770  39.750            1            0 2021-12-31  2021   \n"," 86580                 NaN  30.125            0            1 2021-12-31  2021   \n"," 86581         13050.16499  28.325            2            0 2021-12-31  2021   \n"," 86582         13061.41329  21.250            0            0 2021-12-31  2021   \n"," 86583         13063.79500  40.350            1            0 2021-12-31  2021   \n"," \n","        month  day  Weekday Year_week month_day  NO2_trop_rolling_max_60  \n"," 0          1    1        1    2019-1       1-1                      NaN  \n"," 1          1    1        1    2019-1       1-1                      NaN  \n"," 2          1    1        1    2019-1       1-1                      NaN  \n"," 3          1    1        1    2019-1       1-1                      NaN  \n"," 4          1    1        1    2019-1       1-1                      NaN  \n"," ...      ...  ...      ...       ...       ...                      ...  \n"," 86579     12   31        4    2021-4     12-31                      NaN  \n"," 86580     12   31        4    2021-4     12-31                      NaN  \n"," 86581     12   31        4    2021-4     12-31                      NaN  \n"," 86582     12   31        4    2021-4     12-31                      NaN  \n"," 86583     12   31        4    2021-4     12-31                      NaN  \n"," \n"," [82051 rows x 24 columns],\n","        ID_Zindi      Date     ID        LAT        LON  Precipitation     LST  \\\n"," 0     ID_2MYNQS    1/1/19   PD03  45.289376  11.642394       3.277529     NaN   \n"," 1     ID_P4U5WU    1/1/19   TV03  45.836941  12.510362       0.000000     NaN   \n"," 2     ID_U4KWPK    1/1/19  X5561  45.582894   8.842165       0.000000  282.98   \n"," 3     ID_QGSNTZ    1/1/19  X5953  45.131947  10.015742       1.928031     NaN   \n"," 4     ID_GHSZ6K    1/1/19  X6701  45.186329   9.146666       0.000000     NaN   \n"," ...         ...       ...    ...        ...        ...            ...     ...   \n"," 6571  ID_GUSXU9  12/31/21   TV03  45.836941  12.510362       0.000000  282.58   \n"," 6572  ID_GMVEG1  12/31/21  X5561  45.582894   8.842165       0.000000  285.12   \n"," 6573  ID_GD6HNP  12/31/21  X5953  45.131947  10.015742       0.000000     NaN   \n"," 6574  ID_J7YW1Y  12/31/21  X6701  45.186329   9.146666       0.000000     NaN   \n"," 6575  ID_I4E04N  12/31/21  X6877  45.151743  10.781408       0.000000  273.42   \n"," \n","            AAI  CloudFraction  NO2_strat  NO2_total  NO2_trop  \\\n"," 0    -0.313361       0.771456   0.000024   0.000075       NaN   \n"," 1    -0.229512       0.398208   0.000023   0.000120       NaN   \n"," 2    -0.470822       0.153694   0.000023   0.000171  0.000148   \n"," 3     0.132952       0.756917   0.000024   0.000266       NaN   \n"," 4    -0.198272       0.678858   0.000023   0.000149       NaN   \n"," ...        ...            ...        ...        ...       ...   \n"," 6571 -0.013364       0.000000   0.000032   0.000135  0.000103   \n"," 6572 -0.412887       0.002098   0.000031   0.000201  0.000171   \n"," 6573       NaN            NaN        NaN        NaN       NaN   \n"," 6574 -1.025128       0.476947   0.000031   0.000751       NaN   \n"," 6575 -0.844936       0.460769   0.000032   0.000488       NaN   \n"," \n","       TropopausePressure  lat_cluster  lon_cluster       date  Year  month  \\\n"," 0            14440.02819            1            3 2019-01-01  2019      1   \n"," 1            14434.04790            2            3 2019-01-01  2019      1   \n"," 2            14427.42478            2            0 2019-01-01  2019      1   \n"," 3            14443.09006            0            1 2019-01-01  2019      1   \n"," 4            14440.85840            0            0 2019-01-01  2019      1   \n"," ...                  ...          ...          ...        ...   ...    ...   \n"," 6571         13060.46860            2            3 2021-12-31  2021     12   \n"," 6572         13056.11764            2            0 2021-12-31  2021     12   \n"," 6573                 NaN            0            1 2021-12-31  2021     12   \n"," 6574         13063.22260            0            0 2021-12-31  2021     12   \n"," 6575         13064.08868            0            2 2021-12-31  2021     12   \n"," \n","       day  Weekday Year_week month_day  NO2_trop_rolling_max_60  \n"," 0       1        1    2019-1       1-1                      NaN  \n"," 1       1        1    2019-1       1-1                      NaN  \n"," 2       1        1    2019-1       1-1                      NaN  \n"," 3       1        1    2019-1       1-1                      NaN  \n"," 4       1        1    2019-1       1-1                      NaN  \n"," ...   ...      ...       ...       ...                      ...  \n"," 6571   31        4    2021-4     12-31                      NaN  \n"," 6572   31        4    2021-4     12-31                      NaN  \n"," 6573   31        4    2021-4     12-31                      NaN  \n"," 6574   31        4    2021-4     12-31                      NaN  \n"," 6575   31        4    2021-4     12-31                      NaN  \n"," \n"," [6576 rows x 23 columns])"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["df =pd.concat([train,test])\n","from khwarizm.time_series import Features\n","Features = Features(dataset=df,trainset=train,testset=test,date_feature='Date')\n","Features.rolling_feature('NO2_trop', window=60)"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'stop' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mstop\u001b[49m\n","\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"]}],"source":["stop"]},{"cell_type":"markdown","metadata":{"id":"I8bwdOoRA2k6"},"source":["# Missing Values & Encoding"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-09-07T07:08:45.666325Z","iopub.status.busy":"2024-09-07T07:08:45.665863Z","iopub.status.idle":"2024-09-07T07:08:45.761306Z","shell.execute_reply":"2024-09-07T07:08:45.760284Z","shell.execute_reply.started":"2024-09-07T07:08:45.666280Z"},"id":"9Q7DTxHNA2k6","outputId":"f8468b94-56d1-4ba3-d3a9-86adf5537b8c","trusted":true},"outputs":[{"data":{"text/plain":["(       ID_Zindi        LAT        LON     LST  NO2_strat  NO2_total  NO2_trop  \\\n"," 0         33346  45.601585  11.903551     NaN   0.000024   0.000117       NaN   \n"," 1         19485  45.371005  11.840830     NaN   0.000024   0.000127       NaN   \n"," 2         70785  45.045825  12.060869     NaN   0.000024   0.000086       NaN   \n"," 3         47159  45.104075  11.553241     NaN   0.000024   0.000124       NaN   \n"," 4         58617  45.038758  11.790152     NaN   0.000024   0.000116       NaN   \n"," ...         ...        ...        ...     ...        ...        ...       ...   \n"," 86579     53090  45.498227   9.556232     NaN   0.000032   0.000643       NaN   \n"," 86580     69188  45.142541  10.043836     NaN        NaN        NaN       NaN   \n"," 86581     33315  45.842207   9.351658  284.98   0.000031   0.000153  0.000122   \n"," 86582      9113  45.113503   8.874065     NaN   0.000031   0.000717       NaN   \n"," 86583     38431  45.526473   9.515980     NaN   0.000032   0.000643       NaN   \n"," \n","        TropopausePressure  GT_NO2  lon_cluster       date  Year  month  day  \\\n"," 0             14440.82126  31.000            3 2019-01-01  2019      1    1   \n"," 1             14441.79815  42.000            3 2019-01-01  2019      1    1   \n"," 2             14437.38294  31.000            3 2019-01-01  2019      1    1   \n"," 3             14440.83831  30.000            2 2019-01-01  2019      1    1   \n"," 4             14438.79037  58.000            3 2019-01-01  2019      1    1   \n"," ...                   ...     ...          ...        ...   ...    ...  ...   \n"," 86579         13063.79770  39.750            0 2021-12-31  2021     12   31   \n"," 86580                 NaN  30.125            1 2021-12-31  2021     12   31   \n"," 86581         13050.16499  28.325            0 2021-12-31  2021     12   31   \n"," 86582         13061.41329  21.250            0 2021-12-31  2021     12   31   \n"," 86583         13063.79500  40.350            0 2021-12-31  2021     12   31   \n"," \n","        Weekday  Year_week  month_day  NO2_trop_rolling_max_60  \n"," 0            1          1          0                      NaN  \n"," 1            1          1          0                      NaN  \n"," 2            1          1          0                      NaN  \n"," 3            1          1          0                      NaN  \n"," 4            1          1          0                      NaN  \n"," ...        ...        ...        ...                      ...  \n"," 86579        4         18        116                      NaN  \n"," 86580        4         18        116                      NaN  \n"," 86581        4         18        116                      NaN  \n"," 86582        4         18        116                      NaN  \n"," 86583        4         18        116                      NaN  \n"," \n"," [82051 rows x 18 columns],\n","       ID_Zindi        LAT        LON     LST  NO2_strat  NO2_total  NO2_trop  \\\n"," 0          486  45.289376  11.642394     NaN   0.000024   0.000075       NaN   \n"," 1         4546  45.836941  12.510362     NaN   0.000023   0.000120       NaN   \n"," 2         5459  45.582894   8.842165  282.98   0.000023   0.000171  0.000148   \n"," 3         4788  45.131947  10.015742     NaN   0.000024   0.000266       NaN   \n"," 4         3007  45.186329   9.146666     NaN   0.000023   0.000149       NaN   \n"," ...        ...        ...        ...     ...        ...        ...       ...   \n"," 6571      3068  45.836941  12.510362  282.58   0.000032   0.000135  0.000103   \n"," 6572      3030  45.582894   8.842165  285.12   0.000031   0.000201  0.000171   \n"," 6573      2988  45.131947  10.015742     NaN        NaN        NaN       NaN   \n"," 6574      3496  45.186329   9.146666     NaN   0.000031   0.000751       NaN   \n"," 6575      3306  45.151743  10.781408  273.42   0.000032   0.000488       NaN   \n"," \n","       TropopausePressure  lon_cluster       date  Year  month  day  Weekday  \\\n"," 0            14440.02819            3 2019-01-01  2019      1    1        1   \n"," 1            14434.04790            3 2019-01-01  2019      1    1        1   \n"," 2            14427.42478            0 2019-01-01  2019      1    1        1   \n"," 3            14443.09006            1 2019-01-01  2019      1    1        1   \n"," 4            14440.85840            0 2019-01-01  2019      1    1        1   \n"," ...                  ...          ...        ...   ...    ...  ...      ...   \n"," 6571         13060.46860            3 2021-12-31  2021     12   31        4   \n"," 6572         13056.11764            0 2021-12-31  2021     12   31        4   \n"," 6573                 NaN            1 2021-12-31  2021     12   31        4   \n"," 6574         13063.22260            0 2021-12-31  2021     12   31        4   \n"," 6575         13064.08868            2 2021-12-31  2021     12   31        4   \n"," \n","       Year_week  month_day  NO2_trop_rolling_max_60  \n"," 0             1          0                      NaN  \n"," 1             1          0                      NaN  \n"," 2             1          0                      NaN  \n"," 3             1          0                      NaN  \n"," 4             1          0                      NaN  \n"," ...         ...        ...                      ...  \n"," 6571         18        116                      NaN  \n"," 6572         18        116                      NaN  \n"," 6573         18        116                      NaN  \n"," 6574         18        116                      NaN  \n"," 6575         18        116                      NaN  \n"," \n"," [6576 rows x 17 columns])"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["for df in(train,test):\n","    df.drop(columns=['Date','ID','Precipitation','CloudFraction','AAI','lat_cluster'], axis=1,inplace=True)\n","\n","def encoder(train,test):\n","  le = LabelEncoder()\n","  for df in(train,test):\n","      for col in df.columns:\n","          if df[col].dtype == 'object':\n","              df[col] = le.fit_transform(df[col])\n","  return train,test\n","\n","encoder(train,test)"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["from khwarizm.utils import DataValidationUtils\n","dvu = DataValidationUtils()\n","train = dvu.format_data_types(train)\n","test = dvu.format_data_types(test)"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"data":{"text/plain":["ID_Zindi                            int64\n","LAT                               float64\n","LON                               float64\n","LST                               float64\n","NO2_strat                         float64\n","NO2_total                         float64\n","NO2_trop                          float64\n","TropopausePressure                float64\n","GT_NO2                            float64\n","lon_cluster                         int64\n","date                       datetime64[ns]\n","Year                                int32\n","month                               int32\n","day                                 int32\n","Weekday                             int32\n","Year_week                           int64\n","month_day                           int64\n","NO2_trop_rolling_max_60           float64\n","dtype: object"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["train.dtypes"]},{"cell_type":"markdown","metadata":{"id":"KELbHAFzA2k7"},"source":["# CV and Modeling"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T07:08:45.762929Z","iopub.status.busy":"2024-09-07T07:08:45.762565Z","iopub.status.idle":"2024-09-07T07:09:23.199715Z","shell.execute_reply":"2024-09-07T07:09:23.198396Z","shell.execute_reply.started":"2024-09-07T07:08:45.762873Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["train shape : (65206,), test shape:(16845,)\n"]},{"ename":"DTypePromotionError","evalue":"The DType <class 'numpy.dtypes.DateTime64DType'> could not be promoted by <class 'numpy.dtypes.Float64DType'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.DateTime64DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float32DType'>)","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mDTypePromotionError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[25], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m RandomForestModel \u001b[38;5;241m=\u001b[39m LGBMRegressor()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkhwarizm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_model\n\u001b[0;32m----> 3\u001b[0m \u001b[43mvalidate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRandomForestModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGroupKFold\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtarget_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGT_NO2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/workspaces/khwarizm/khwarizm/feature_selection.py:70\u001b[0m, in \u001b[0;36mvalidate_model\u001b[0;34m(model, cv, n_splits, dataset, target_col, groups)\u001b[0m\n\u001b[1;32m     68\u001b[0m     train_v, test_v \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39miloc[train_index], dataset\u001b[38;5;241m.\u001b[39miloc[test_index]\n\u001b[1;32m     69\u001b[0m     stds\u001b[38;5;241m.\u001b[39mappend(test_v[target_col]\u001b[38;5;241m.\u001b[39mstd())\n\u001b[0;32m---> 70\u001b[0m     scores\u001b[38;5;241m.\u001b[39mappend(\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_col\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(scores)\u001b[38;5;241m.\u001b[39mmean()\n","File \u001b[0;32m/workspaces/khwarizm/khwarizm/feature_selection.py:32\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(model, trainset, testset, target_col)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(model, trainset, testset, target_col):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m#with suppress_output(): \u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtarget_col\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrainset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtarget_col\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     y_predicted \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(testset\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39mtarget_col))\n\u001b[1;32m     34\u001b[0m     valid_idx \u001b[38;5;241m=\u001b[39m testset[target_col]\u001b[38;5;241m.\u001b[39mnotna()\n","File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/lightgbm/sklearn.py:1189\u001b[0m, in \u001b[0;36mLGBMRegressor.fit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m   1173\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1174\u001b[0m     X: _LGBM_ScikitMatrixLike,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1186\u001b[0m     init_model: Optional[Union[\u001b[38;5;28mstr\u001b[39m, Path, Booster, LGBMModel]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1187\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLGBMRegressor\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1189\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n","File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/lightgbm/sklearn.py:955\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    952\u001b[0m evals_result: _EvalResultDict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    953\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[0;32m--> 955\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evals_result \u001b[38;5;241m=\u001b[39m evals_result\n\u001b[1;32m    967\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_best_iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\u001b[38;5;241m.\u001b[39mbest_iteration\n","File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/lightgbm/engine.py:282\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;66;03m# construct booster\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 282\u001b[0m     booster \u001b[38;5;241m=\u001b[39m \u001b[43mBooster\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_valid_contain_train:\n\u001b[1;32m    284\u001b[0m         booster\u001b[38;5;241m.\u001b[39mset_train_data_name(train_data_name)\n","File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/lightgbm/basic.py:3637\u001b[0m, in \u001b[0;36mBooster.__init__\u001b[0;34m(self, params, train_set, model_file, model_str)\u001b[0m\n\u001b[1;32m   3630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_network(\n\u001b[1;32m   3631\u001b[0m         machines\u001b[38;5;241m=\u001b[39mmachines,\n\u001b[1;32m   3632\u001b[0m         local_listen_port\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal_listen_port\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   3633\u001b[0m         listen_time_out\u001b[38;5;241m=\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_out\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m120\u001b[39m),\n\u001b[1;32m   3634\u001b[0m         num_machines\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_machines\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   3635\u001b[0m     )\n\u001b[1;32m   3636\u001b[0m \u001b[38;5;66;03m# construct booster object\u001b[39;00m\n\u001b[0;32m-> 3637\u001b[0m \u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3638\u001b[0m \u001b[38;5;66;03m# copy the parameters from train_set\u001b[39;00m\n\u001b[1;32m   3639\u001b[0m params\u001b[38;5;241m.\u001b[39mupdate(train_set\u001b[38;5;241m.\u001b[39mget_params())\n","File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/lightgbm/basic.py:2576\u001b[0m, in \u001b[0;36mDataset.construct\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2571\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_init_score_by_predictor(\n\u001b[1;32m   2572\u001b[0m                 predictor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predictor, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, used_indices\u001b[38;5;241m=\u001b[39mused_indices\n\u001b[1;32m   2573\u001b[0m             )\n\u001b[1;32m   2574\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2575\u001b[0m     \u001b[38;5;66;03m# create train\u001b[39;00m\n\u001b[0;32m-> 2576\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2577\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2578\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2579\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2580\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2581\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2582\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2583\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predictor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2588\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2589\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfree_raw_data:\n\u001b[1;32m   2590\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/lightgbm/basic.py:2106\u001b[0m, in \u001b[0;36mDataset._lazy_init\u001b[0;34m(self, data, label, reference, weight, group, init_score, predictor, feature_name, categorical_feature, params, position)\u001b[0m\n\u001b[1;32m   2104\u001b[0m     categorical_feature \u001b[38;5;241m=\u001b[39m reference\u001b[38;5;241m.\u001b[39mcategorical_feature\n\u001b[1;32m   2105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, pd_DataFrame):\n\u001b[0;32m-> 2106\u001b[0m     data, feature_name, categorical_feature, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpandas_categorical \u001b[38;5;241m=\u001b[39m \u001b[43m_data_from_pandas\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpandas_categorical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpandas_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2111\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2113\u001b[0m \u001b[38;5;66;03m# process for args\u001b[39;00m\n\u001b[1;32m   2114\u001b[0m params \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;28;01mif\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m params\n","File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/lightgbm/basic.py:845\u001b[0m, in \u001b[0;36m_data_from_pandas\u001b[0;34m(data, feature_name, categorical_feature, pandas_categorical)\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[38;5;66;03m# so that the target dtype considers floats\u001b[39;00m\n\u001b[1;32m    844\u001b[0m df_dtypes\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m--> 845\u001b[0m target_dtype \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult_type\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdf_dtypes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    848\u001b[0m     _pandas_to_numpy(data, target_dtype\u001b[38;5;241m=\u001b[39mtarget_dtype),\n\u001b[1;32m    849\u001b[0m     feature_name,\n\u001b[1;32m    850\u001b[0m     categorical_feature,\n\u001b[1;32m    851\u001b[0m     pandas_categorical,\n\u001b[1;32m    852\u001b[0m )\n","\u001b[0;31mDTypePromotionError\u001b[0m: The DType <class 'numpy.dtypes.DateTime64DType'> could not be promoted by <class 'numpy.dtypes.Float64DType'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.DateTime64DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float32DType'>)"]}],"source":["RandomForestModel = LGBMRegressor()\n","from khwarizm.feature_selection import validate_model\n","validate_model(model=RandomForestModel,cv='GroupKFold', n_splits=5,dataset=train,target_col='GT_NO2', groups=groups)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-09-07T07:09:23.201586Z","iopub.status.busy":"2024-09-07T07:09:23.201247Z","iopub.status.idle":"2024-09-07T07:10:00.336117Z","shell.execute_reply":"2024-09-07T07:10:00.334753Z","shell.execute_reply.started":"2024-09-07T07:09:23.201548Z"},"id":"HHaRM8N7A2k8","outputId":"9b6e1404-4006-457b-b5eb-d2c69d7f4d95","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007191 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2971\n","[LightGBM] [Info] Number of data points in the train set: 65206, number of used features: 18\n","[LightGBM] [Info] Start training from score 23.997347\n","std: 17.06148359415839\n","score: 10.457133906490098\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006702 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2973\n","[LightGBM] [Info] Number of data points in the train set: 65234, number of used features: 18\n","[LightGBM] [Info] Start training from score 24.169432\n"]},{"name":"stderr","output_type":"stream","text":["/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["std: 19.215238775849844\n","score: 10.664819793296964\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005468 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2970\n","[LightGBM] [Info] Number of data points in the train set: 65834, number of used features: 18\n","[LightGBM] [Info] Start training from score 24.290743\n"]},{"name":"stderr","output_type":"stream","text":["/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["std: 18.587381576876247\n","score: 10.61840582290597\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005712 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2970\n","[LightGBM] [Info] Number of data points in the train set: 65824, number of used features: 18\n","[LightGBM] [Info] Start training from score 24.928707\n"]},{"name":"stderr","output_type":"stream","text":["/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["std: 14.468189480112546\n","score: 9.036741834674645\n"]},{"name":"stderr","output_type":"stream","text":["/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[11], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m rmse \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_idx, test_idx \u001b[38;5;129;01min\u001b[39;00m cv\u001b[38;5;241m.\u001b[39msplit(train\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGT_NO2\u001b[39m\u001b[38;5;124m'\u001b[39m), train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGT_NO2\u001b[39m\u001b[38;5;124m'\u001b[39m], groups\u001b[38;5;241m=\u001b[39mgroups):\n\u001b[0;32m---> 37\u001b[0m     train_v, test_v \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m[train_idx], train\u001b[38;5;241m.\u001b[39miloc[test_idx]\n\u001b[1;32m     38\u001b[0m     stds\u001b[38;5;241m.\u001b[39mappend(test_v[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGT_NO2\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstd())\n\u001b[1;32m     39\u001b[0m     rmse\u001b[38;5;241m.\u001b[39mappend(validate(train_v, test_v, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGT_NO2\u001b[39m\u001b[38;5;124m'\u001b[39m))\n","File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/indexing.py:161\u001b[0m, in \u001b[0;36mIndexingMixin.iloc\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mIndexingMixin\u001b[39;00m:\n\u001b[1;32m    157\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;124;03m    Mixin for adding .loc/.iloc/.at/.iat to Dataframes and Series.\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 161\u001b[0m     \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21miloc\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _iLocIndexer:\n\u001b[1;32m    163\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03m        Purely integer-location based indexing for selection by position.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;124;03m        2  1000  3000\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;124;03m        \"\"\"\u001b[39;00m\n\u001b[1;32m    303\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _iLocIndexer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["\"\"\"model = CatBoostRegressor(\n","    iterations=1000,        \n","    learning_rate=0.1,      \n","    depth=6,                \n","    loss_function='RMSE',   \n","    eval_metric='RMSE',     \n","    random_seed=seed,          \n","    verbose=100,\n","   \n",")\n","\"\"\"\n","\n","#model = CatBoostRegressor(random_state=seed)\n","#model = XGBRegressor(random_state= 7)\n","model =  LGBMRegressor(random_state=7)\n","n_splits = 5\n","n = train['GT_NO2'].count()\n","num_bins = int(1 + np.log2(n))\n","cv = GroupKFold(n_splits=n_splits)\n","\n","def validate(trainset, testset, target_col):\n","\n","    model.fit(trainset.drop(columns=target_col), trainset[target_col])\n","    pred = model.predict(testset.drop(columns=target_col))\n","    valid_idx = testset[target_col].notna()\n","    valid_testset = testset[target_col][valid_idx]\n","    valid_pred = pred[valid_idx]\n","    print('std:', valid_testset.std())\n","    score = mean_squared_error(valid_testset, valid_pred, squared=False)\n","    print('score:', score)\n","\n","    return score\n","stds = []\n","rmse = []\n","\n","for train_idx, test_idx in cv.split(train.drop(columns='GT_NO2'), train['GT_NO2'], groups=groups):\n","    train_v, test_v = train.iloc[train_idx], train.iloc[test_idx]\n","    stds.append(test_v['GT_NO2'].std())\n","    rmse.append(validate(train_v, test_v, 'GT_NO2'))\n","\n","print('RMSE:', np.array(rmse).mean())\n","print('RMSE std:', np.array(rmse).std())\n","print('Standard Deviations:', stds)\n","print('RMSEs Deviations:', rmse)"]},{"cell_type":"code","execution_count":61,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T07:10:00.456335Z","iopub.status.busy":"2024-09-07T07:10:00.455925Z","iopub.status.idle":"2024-09-07T07:10:00.476162Z","shell.execute_reply":"2024-09-07T07:10:00.474948Z","shell.execute_reply.started":"2024-09-07T07:10:00.456292Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: GBMRegres\n","Validation Type: StratifiedGroupKFold\n","Number of Folds: 5\n","Shuffle: Yes\n","Model Parameters:\n","  boosting_type: gbdt\n","  class_weight: None\n","  colsample_bytree: 1.0\n","  importance_type: split\n","  learning_rate: 0.1\n","  max_depth: -1\n","  min_child_samples: 20\n","  min_child_weight: 0.001\n","  min_split_gain: 0.0\n","  n_estimators: 100\n","  n_jobs: None\n","  num_leaves: 31\n","  objective: None\n","  random_state: 7\n","  reg_alpha: 0.0\n","  reg_lambda: 0.0\n","  subsample: 1.0\n","  subsample_for_bin: 200000\n","  subsample_freq: 0\n","\n","Additional Notes:\n","  -  as the evaluation metric.\n"]}],"source":["def generate_specifications(model_name, num_folds, model_params, validation_type='StratifiedGroupKFold', shuffle=True):\n","    specs = []\n","    specs.append(f\"Model: {model_name}\")\n","    specs.append(f\"Validation Type: {validation_type}\")\n","    specs.append(f\"Number of Folds: {num_folds}\")\n","    specs.append(f\"Shuffle: {'Yes' if shuffle else 'No'}\")\n","    \n","    # Adding model parameters\n","    specs.append(\"Model Parameters:\")\n","    for param, value in model_params.items():\n","        specs.append(f\"  {param}: {value}\")\n","    \n","    # Adding any additional info (if needed)\n","    specs.append(\"\\nAdditional Notes:\")\n","    specs.append(\"  -  as the evaluation metric.\")\n","    \n","    # Joining all specifications into a single string\n","    return \"\\n\".join(specs)\n","\n","# Example usage\n","\n","specifications = generate_specifications(model_name=str(model)[1:10], num_folds=n_splits, model_params=model.get_params())\n","print(specifications)"]},{"cell_type":"markdown","metadata":{"id":"7j4l5J1DPJIZ"},"source":["# inference"]},{"cell_type":"code","execution_count":63,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T07:10:00.477975Z","iopub.status.busy":"2024-09-07T07:10:00.477536Z","iopub.status.idle":"2024-09-07T07:10:08.961974Z","shell.execute_reply":"2024-09-07T07:10:08.960187Z","shell.execute_reply.started":"2024-09-07T07:10:00.477882Z"},"id":"cp0d4T3DA2k-","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001309 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 3012\n","[LightGBM] [Info] Number of data points in the train set: 48596, number of used features: 18\n","[LightGBM] [Info] Start training from score 22.909476\n"]},{"ename":"ValueError","evalue":"Number of features of the model must match the input. Model n_features_ is 18 and input n_features is 14","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[63], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(train\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGT_NO2\u001b[39m\u001b[38;5;124m'\u001b[39m),train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGT_NO2\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 2\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#sub_df = pd.DataFrame({'id': test_id,'GT_NO2':y_pred})\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#sub_df.to_csv('submission9277409514290884.csv', index=False)\u001b[39;00m\n","File \u001b[0;32m~/Downloads/computerscience/AirQo/PM2.5-Prediction/AirQo-Virtual-Enviroment/lib/python3.11/site-packages/lightgbm/sklearn.py:1010\u001b[0m, in \u001b[0;36mLGBMModel.predict\u001b[0;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, validate_features, **kwargs)\u001b[0m\n\u001b[1;32m   1008\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_features \u001b[38;5;241m!=\u001b[39m n_features:\n\u001b[0;32m-> 1010\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1011\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of features of the model must \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1012\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatch the input. Model n_features_ is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1013\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput n_features is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1014\u001b[0m     )\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;66;03m# retrieve original params that possibly can be used in both training and prediction\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;66;03m# and then overwrite them (considering aliases) with params that were passed directly in prediction\u001b[39;00m\n\u001b[1;32m   1017\u001b[0m predict_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_params(stage\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features_ is 18 and input n_features is 14"]}],"source":["\n","model.fit(train.drop(columns='GT_NO2'),train['GT_NO2'])\n","y_pred = model.predict(test)\n","#sub_df = pd.DataFrame({'id': test_id,'GT_NO2':y_pred})\n","#sub_df.to_csv('submission9277409514290884.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-07T07:10:08.963077Z","iopub.status.idle":"2024-09-07T07:10:08.963670Z","shell.execute_reply":"2024-09-07T07:10:08.963399Z","shell.execute_reply.started":"2024-09-07T07:10:08.963367Z"},"id":"Z9ITwLs3PQWI","trusted":true},"outputs":[],"source":["plt.figure(figsize=(16, 7))\n","sns.lineplot(x=train_date, y=train.GT_NO2, color='blue', label='Train')\n","sns.lineplot(x=test_date, y=y_pred, color='red', label='Prediction')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-07T07:10:08.965376Z","iopub.status.idle":"2024-09-07T07:10:08.965818Z","shell.execute_reply":"2024-09-07T07:10:08.965627Z","shell.execute_reply.started":"2024-09-07T07:10:08.965603Z"},"id":"9m6QE2TgA2k-","trusted":true},"outputs":[],"source":["importances = model.feature_importances_\n","names = model.feature_names_\n","fi = pd.DataFrame({'Feature': names,\n","                   'importances': importances})\n","fi = fi.sort_values(by='importances', ascending=False)\n","\n","fi.plot(kind='bar', x='Feature', y='importances', legend=False, figsize=(10, 6))\n","plt.title('Feature Importances')\n","plt.xlabel('Features')\n","plt.ylabel('Importance')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-07T07:10:08.967208Z","iopub.status.idle":"2024-09-07T07:10:08.967645Z","shell.execute_reply":"2024-09-07T07:10:08.967454Z","shell.execute_reply.started":"2024-09-07T07:10:08.967432Z"},"id":"NLSlX2mtA2k-","trusted":true},"outputs":[],"source":["train.columns"]}],"metadata":{"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5270243,"sourceId":8770223,"sourceType":"datasetVersion"}],"dockerImageVersionId":30761,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.1"}},"nbformat":4,"nbformat_minor":4}
